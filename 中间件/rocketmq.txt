一、环境搭建
1.启动NameServer
	#启动命令
	> nohup sh bin/mqnamesrv &
	#查看日志
	> tail -f ~/logs/rocketmqlogs/namesrv.log
	
2.启动Broker
	#启动命令
	> nohup sh bin/mqbroker -n localhost:9876 &
	#查看日志
	> tail -f ~/logs/rocketmqlogs/broker.log
	
3.测试生产者和消费者
	#配置环境变量
	> export NAMESRV_ADDR=localhost:9876
	#测试生产者
	> sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer
	SendResult [sendStatus=SEND_OK, msgId= ...
	#测试消费者
	> sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer
	ConsumeMessageThread_%d Receive New Messages: [MessageExt...
	
4.关闭NameServer和Broker
	> sh bin/mqshutdown broker
	The mqbroker(36695) is running...
	Send shutdown request to mqbroker(36695) OK

	> sh bin/mqshutdown namesrv
	The mqnamesrv(36664) is running...
	Send shutdown request to mqnamesrv(36664) OK
	
*****************WARN*****************

安装控制台的时候，linux需要关闭防火墙，命令如下：
sudo systemctl stop firewalld

*****************WARN*****************

*****************INFO*****************

cmd使用maven编译rocketmq项目的命令：
mvn clean package -Dmaven.test.skip=true

*****************INFO*****************


Broker集群
2主2从集群模式:
在conf/2m-2s-async中配置两主两从模式。
配置文件：
broker-a.properties	master1
broker-a-s.properties slave1
broker-b.properties master2
broker-b-s.properties slave2

broker配置信息：
#指定整个broker集群名称/RocketMQ集群的名称
brokerClusterName=DefaultCluster
#指定master-slave集群的名称。一个RocketMQ集群可以包含多个master-slave集群
brokerName=broker-a
#master的brokerId为0，其他为slave
brokerId=0
#指定删除消息存储过期文件的时间为凌晨4点
deleteWhen=04
#指定未发生更新消息存储文件的保留时长为48小时，48小时后过期，将会被删除
fileReservedTime=48
#指定当前broker为异步复制master
brokerRole=ASYNC_MASTER
#指定刷盘策略为异步刷盘
flushDiskType=ASYNC_FLUSH
#指定Name Server的地址
namesrvAddr=192.168.239.67:9876;192.168.239.68:9876

slave配置信息：
brokerClusterName=DefaultCluster
#指定这是另外一个master-slave集群
brokerName=broker-b
#slave的brokerId非0
brokerId=1
deleteWhen=04
fileReservedTime=48
#指定当前broker为slave
brokerRole=SLAVE
flushDiskType=ASYNC_FLUSH
namesrvAddr=192.168.239.67:9876;192.168.239.68:9876
#指定Broker对外提供服务的端口，即Broker与producer与consumer通信端口。默认10911。
#由于当前主机同时充当着master1与slave2，而前面的master1使用的是默认端口。这里需要
#将这两个端口加以区分，以区分出master1与slave2
listenPort=11911
#指定消息存储相关路径。默认路径为~/store目录，由于当前主机同时充当着master1与slave2，master1
#使用的是默认路径，这里就需要再指定一个不同的路径
storePathRootDir=~/store-s
storePathCommitLog=~/store-s/commitlog
storePathConsumeQueue=~/store-s/consumequeue
storePathIndex=~/store-s/index
storeCheckpoint=~/store-s/checkpoint
abortFile=~/store-s/abort

启动集群中的NameServer：
	nohup sh bin/mqnamesrv &

启动master：
启动集群中的brokerA[第一台服务器]（根据配置文件启动）
	nohup bin/mqbroker -c conf/2m-2s-async/broker-a.properties &
	
启动集群中的brokerB[第二台服务器]（根据配置文件启动）
	nohup bin/mqbroker -c conf/2m-2s-async/broker-b.properties &
	
启动slave：
启动集群中的slave2[第一台服务器]（根据配置文件启动）
	nohup bin/mqbroker -c conf/2m-2s-async/broker-b-s.properties & 

启动集群中的slave1[第二台服务器]（根据配置文件启动）
	nohup bin/mqbroker -c conf/2m-2s-async/broker-a-s.properties & 
	
************~/store下的文件************

[root@rocketmqOS1 store]# cd ~/store/
[root@rocketmqOS1 store]# ll
总用量 8
-rw-r--r--. 1 root root    0 4月  10 19:34 abort
-rw-r--r--. 1 root root 4096 4月  10 19:57 checkpoint
drwxr-xr-x. 2 root root   34 4月   9 17:21 commitlog
drwxr-xr-x. 2 root root  246 4月  10 19:57 config
drwxr-xr-x. 3 root root   23 4月   9 17:19 consumequeue
drwxr-xr-x. 2 root root   31 4月  10 19:30 index
-rw-r--r--. 1 root root    4 4月  10 19:34 lock

abort:该文件在Broker启动后会自动创建，正常关闭Broker，该文件会消失，若在没有启动
Broker的情况下，发现这个文件是存在的，则说明之前的Broker的关闭是非正常关闭的

checkpoint:其中存储着commitlog、consumequeue、index文件的最后刷盘时间

commitlog:其中存放着commitlog文件，而消息是写在commitlog文件中的

config:存放着Broker运行期间的一些配置数据

consumequeue:其中存放着consumequeue文件，队列就存放在这个目录中
	consumequeue文件是commitlog的索引文件，每个consumequeue文件可以包含30w个索引条目
	，每个索引条目包含了三个消息重要属性mappedFile文件中的偏移量CommitLog Offset、消息长度、消息Tag的hashcode值，
	这三个属性占20个字节，所以每个文件的大小固定为30w * 20字节

	一个consumequeue文件中所有消息的Topic一定是相同的。但每条消息的Tag可能是不同的
index:其中存放着消息索引文件indexFile
	通过用户指定的key[索引数据是存在key的消息发送到Broker时写入的]进行查询
	indexFile结构：
	indexHeader + slot + indexs
	
	indexFile文件是什么时候创建的？
	*当第一条带key的消息发送过来后，系统发现没有indexFile，此时会创建第一个indexFile文件
	*当第一个indexFile中挂载的index索引单元数量超出2000w个时，会创建一个新的indexFile。当带key的
		消息发送过来后，系统会找到最新的indexFile，并从其indexHeader的最后4个字节中读取到indexCount。
		若indexCount >= 2000w时，会创建一个新的indexFile。
	#一个indexFile的最大Size为(40 + 500w * 4 + 2000w * 20)字节
	
	indexFile查询流程:
	1.计算指定消息key的slot槽位序号：
		slot槽位序号 = key的hash % 500w
	2.计算槽位序号为n的slot在indexFile中的起始位置
		slot(n)位置 = 40 + (n - 1) * 4
	3.计算indexNo为m的index在indexFile中的位置：
		index(m)位置 = 40 + 500w * 4 + (m - 1) * 20
	
lock:运行期间使用到的全局资源锁

************~/store下的文件************

消息写入步骤：
*一条消息进入到Broker后经历了以下几个过程才最终被持久化。
*Broker根据queueld，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset
*将queueld、queueOffset等数据，与消息一起封装为消息单元·将消息单元写入到commitlog
*同时，形成消息索引条目
*将消息索引条目分发到相应的consumerqueue



消息拉取步骤：
*当Consumer来拉取消息时会经历以下几个步骤:
*Consumer获取到其要消费消息所在Queue的消费偏移量offset，计算出其要消费消息的消息offset。
	消费偏移量offset即消费进度，consumer对某个Queue的消费offset，即消费到Queue的第几条消息
	消息offset = 消费偏移量offset + 1 （下一个需要消费的消息）
*Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。
*Broker计算在该consumequeue中的queueOffset。
	queueOffset = 消息offset * 20字节 （偏移量CommitLog Offset、消息长度、消息Tag的hashcode值占20个字节）
*从该queueOffset处开始向后查找第一个指定Tag的索引条目。
*解析该索引条目的前8个字节，即可定位到该消息在commitlog中的commitlog offset·从对应commitlog offset中读取消息单元，并发送给Consumer


***************消息消费***************
推拉消费类型：
	拉取式消费（pull）：Consumer主动从Broker中拉取消息，需要应用去实现对关联Queue的遍历，实时性差，但便于控制消息的拉取
	推送式消费（push）：Broker接收到数据后主动推送给Consumer。封装对Queue的遍历，实时性强但是消耗更多的系统资源


consumer消费方式：
	广播消费模式：Topic中的每条消息都会发送到Consumer Group中的每个Consumer下，消费进度由Consumer保存
	集群消费模式：Topic中的每条消息都会发送到Consumer Group中的一个Consumer下，消费进度由Broker保存

查看Broker中的消费进度：
	[root@rocketmqOS config]# cd ~/store/config/
	[root@rocketmqOS config]# cat consumerOffset.json
	{
			"offsetTable":{
					"TopicTest@please_rename_unique_group_name_4":{0:500,1:500,2:500,3:500
					},
					"%RETRY%please_rename_unique_group_name_4@please_rename_unique_group_name_4":{0:0
					}
			}
	}[root@rocketmqOS config]# 

	在用户桌面下的config/consumerOffset.json文件中存着消费着的消费进度
		对应的Topic@消费者组						  {0、1、2、3四个消费者对应的消费进度}
		"TopicTest@please_rename_unique_group_name_4":{0:500,1:500,2:500,3:500

***************消息消费***************

*************Rebalance机制*************

一个消费着消费5个Queue，如果此时加入一个Consumer，那么会分2个给另一个Consumer消费
目的：提高消息的并行消费能力

Rebalance限制：
	如果消费者超过了Queue的数量时，多余的Consumer不参与消费

Rebalance危害：
	消费暂停：处罚Rebalance时，原Consumer会暂停消费
	消费重复：新Consumer会接着之前的消费Offest继续消费，而默认情况下，offest是异步提交的，从而导致Broker的offest
		与Consumer的实际消费的消息不一样，因此可能导致重复消费
	消费冲刺：由于Rebalance可能导致重复消费，如果需要重复消费的消息过多，或者因为Rebalance暂停时挤压了部分消息。
		那么可能会导致在Rebalance之后瞬间需要消费很多消息

Rebalance产生的原因：
	1.消费者所订阅Topic的Queue数量发生变化
	2.消费者组中消费者Consumer数量发生变化
	1)Queue数量发生变化场景：
		Broker扩容或缩容
		Broker升级运维
		Broker与NameServer网络异常
		Queue扩容或缩容
	2)消费着数量发生变化的场景：
		Consumer Group扩容或缩容
		Consumer升级运维
		Consumer与NameServer网络异常

Rebalance过程：
	在Broker中维护着Topic中Queue信息、Consumer Group中的Consumer信息，当发现消费者所订阅的Queue数量发生
	变化或消费组中消费者的数量发生变化，立即向Consumer Group中每个实例发出Rebalance通知
		*TopicConfigManager：key是topic名称，value是TopicConfig。TopicConfig中维护着该Topic中所有Queue数据
		*ConsumerManager：key是Consumer Group ID，value是ConsumerGroupInfo。ConsumerGroupInfo中维护着该Group中所有Consumer实例数据。
		*ConsumerOffsetManager：key为Topic与订阅该Topic的Group的组合，value是一个内层Map。内层Map的key为QueueID，内层Map的value为该Queue的消费进度offest。

	Consumer实例接收到通知后会采用Queue分配算法自己获取到相应的Queue
	
*************Rebalance机制*************

课程：57